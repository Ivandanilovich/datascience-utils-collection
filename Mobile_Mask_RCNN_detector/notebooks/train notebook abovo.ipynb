{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib, imgaug, cv2, time, re, math, random, sys, os, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "\n",
    "from mmrcnn.config import Config\n",
    "import tqdm\n",
    "from mmrcnn import model as modellib,utils,visualize\n",
    "from mmrcnn.model import log\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "DEFAULT_WEIGHTS = os.path.join(ROOT_DIR, \"mobile_mask_rcnn_coco.h5\")\n",
    "\n",
    "from mmrcnn.visualize import display_instances\n",
    "from mmrcnn.config  import Config\n",
    "from mmrcnn.visualize import display_instances\n",
    "from mmrcnn.utils import extract_bboxes\n",
    "from mmrcnn.utils import compute_ap\n",
    "from mmrcnn.model import load_image_gt\n",
    "from mmrcnn.model import mold_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASS_LIST = ['1','2','3','4','7']\n",
    "CLASS_LIST = ['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../../select from activecam/coco/train.txt', 'r') as f:\n",
    "#     train = f.read().split('\\n')[:-1]\n",
    "# with open('../../select from activecam/coco/val.txt', 'r') as f:\n",
    "#     test = f.read().split('\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,test=[],[]\n",
    "# for i in [j.split('.')[0] for j in os.listdir('../data')]:\n",
    "#     if i=='':\n",
    "#         continue\n",
    "#     if random.random()>0.8:\n",
    "#         test.append(i)\n",
    "#     else:\n",
    "#         train.append(i)\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test), len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('test.pickle', 'wb') as handle:\n",
    "#     pickle.dump(test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('train.pickle', 'wb') as handle:\n",
    "#     pickle.dump(train, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l=[]\n",
    "# print(len(test))\n",
    "# for i in test_set.image_ids:\n",
    "#     original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "#         modellib.load_image_gt(test_set, config, \n",
    "#                            i, use_mini_mask=False)\n",
    "#     i = test_set.image_info[i]['id']\n",
    "#     if gt_class_id[0]!=4:\n",
    "#         continue\n",
    "#     if random.random()>0.5:\n",
    "#         l.append(i)\n",
    "# test=list(set(test)-set(l))\n",
    "# print(len(test))\n",
    "\n",
    "# l=[]\n",
    "# print(len(train))\n",
    "# for i in train_set.image_ids:\n",
    "#     original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "#         modellib.load_image_gt(train_set, config, \n",
    "#                            i, use_mini_mask=False)\n",
    "#     i = train_set.image_info[i]['id']\n",
    "#     if gt_class_id[0]!=4:\n",
    "#         continue\n",
    "#     if random.random()>0.5:\n",
    "#         l.append(i)\n",
    "# train=list(set(train)-set(l))\n",
    "# print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('../images')\n",
    "os.mkdir('../images/')\n",
    "for i in test+train:\n",
    "    pic = plt.imread('../../raw/imported/{}.jpg'.format(re.sub('_','/',i)))\n",
    "    pic  = cv2.resize(pic, (256,256), cv2.INTER_AREA)\n",
    "    matplotlib.image.imsave('../images/{}.jpg'.format(i), pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmrcnn.utils import Dataset\n",
    "class MyDataset(Dataset):\n",
    "    def load_dataset(self, data):\n",
    "        for i, cls in enumerate(CLASS_LIST):\n",
    "            self.add_class(\"dataset\", i, cls)\n",
    "        for i in data:\n",
    "                ann_path = os.path.join('../data/', i+'.xml')\n",
    "                image_id = i.split('.')[0]\n",
    "                with open(ann_path, 'r') as filetext:\n",
    "                    s = filetext.read()\n",
    "                    s = re.sub(\"^\\s+|\\n|\\r|\\s+$\", '', s)\n",
    "                    imname = re.findall('<filename>.*?</filename>', s)[0][7+3:-8-3]\n",
    "                im_path = os.path.join('../images/', imname)\n",
    "                self.add_image('dataset', image_id=image_id, path=im_path, annotation=ann_path)\n",
    "\n",
    "    def extract_boxes(self, filename):\n",
    "        with open(filename, 'r') as filetext:\n",
    "            s = filetext.read()\n",
    "            s = re.sub(\"^\\s+|\\n|\\r|\\s+$\", '', s)\n",
    "        boxes = list()\n",
    "        imname = re.findall('<filename>.*?</filename>', s)[0][7+3:-8-3]\n",
    "        width = int(int(re.findall('<width>.*?</width>', s)[0][7:-8]))\n",
    "        height = int(int(re.findall('<height>.*?</height>', s)[0][8:-9]))\n",
    "        for box in re.findall('<object>.*?</object>', s):\n",
    "            name = re.findall('<name>.*?</name>', box)[0][6:-7]\n",
    "            xmin = float(re.findall('<xmin>.*?</xmin>', box)[0][6:-7])\n",
    "            ymin = float(re.findall('<ymin>.*?</ymin>', box)[0][6:-7])\n",
    "            xmax = float(re.findall('<xmax>.*?</xmax>', box)[0][6:-7])\n",
    "            ymax = float(re.findall('<ymax>.*?</ymax>', box)[0][6:-7])\n",
    "            coors = [int(xmin/float(width)*256), \n",
    "                     int(ymin/float(height)*256), \n",
    "                     int(xmax/float(width)*256), \n",
    "                     int(ymax/float(height)*256), \n",
    "#                      name\n",
    "                     'body'\n",
    "                    ]\n",
    "            boxes.append(coors)\n",
    "        return boxes, 512, 512\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        path = info['annotation']\n",
    "        boxes, w, h = self.extract_boxes(path)\n",
    "        masks = np.zeros([h, w, len(boxes)], dtype='uint8')\n",
    "        class_ids = list()\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            row_s, row_e = box[1], box[3]\n",
    "            col_s, col_e = box[0], box[2]\n",
    "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
    "            class_ids.append(self.class_names.index(str(box[4])))\n",
    "        return masks, np.asarray(class_ids, dtype='int32')\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n",
    "\n",
    "train_set = MyDataset()\n",
    "train_set.load_dataset(train) \n",
    "train_set.prepare()\n",
    "\n",
    "test_set = MyDataset()\n",
    "test_set.load_dataset(test) \n",
    "test_set.prepare()\n",
    "\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "print('Test: %d' % len(test_set.image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=[],[]\n",
    "for i in train_set.image_ids:\n",
    "    image_id = i\n",
    "    image = train_set.load_image(image_id)\n",
    "    mask, class_ids = train_set.load_mask(image_id)\n",
    "    bbox = extract_bboxes(mask)\n",
    "    for b in bbox:\n",
    "        x.append(b[2]-b[0])\n",
    "        y.append(b[3]-b[1])\n",
    "for i in test_set.image_ids:\n",
    "    image_id = i\n",
    "    image = test_set.load_image(image_id)\n",
    "    mask, class_ids = test_set.load_mask(image_id)\n",
    "    bbox = extract_bboxes(mask)\n",
    "    for b in bbox:\n",
    "        x.append(b[2]-b[0])\n",
    "        y.append(b[3]-b[1])\n",
    "plt.hist(x)\n",
    "plt.hist(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    image_id = i\n",
    "    image = train_set.load_image(image_id)\n",
    "    mask, class_ids = train_set.load_mask(image_id)\n",
    "    bbox = extract_bboxes(mask)\n",
    "    display_instances(image, bbox, mask, class_ids, train_set.class_names, show_mask=True)\n",
    "for i in range(2):\n",
    "    image_id = i\n",
    "    image = test_set.load_image(image_id)\n",
    "    mask, class_ids = test_set.load_mask(image_id)\n",
    "    bbox = extract_bboxes(mask)\n",
    "    display_instances(image, bbox, mask, class_ids, train_set.class_names, show_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mConfig(Config):\n",
    "    NAME = \"mmrcnn_abovo\"\n",
    "    BATCH_SIZE = 4\n",
    "    IMAGES_PER_GPU = 4\n",
    "    GPU_COUNT = 1\n",
    "\n",
    "    NUM_CLASSES = 1 + len(CLASS_LIST)  # COCO has 80 classes (1+80)\n",
    "\n",
    "    BACKBONE = \"mobilenetv1\"\n",
    "\n",
    "    BACKBONE_STRIDES = [4, 8, 16, 32, 64] #ResNet\n",
    "\n",
    "    #RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256) #ResNet\n",
    "    RPN_ANCHOR_SCALES = (75,100,125,150,175)\n",
    "\n",
    "#     MINI_MASK_SHAPE = (56, 56) #ResNet\n",
    "    MINI_MASK_SHAPE = (28, 28)\n",
    "\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    IMAGE_MIN_DIM = 256\n",
    "\n",
    "    #TRAIN_ROIS_PER_IMAGE = 200 #ResNet\n",
    "    TRAIN_ROIS_PER_IMAGE = 128\n",
    "    \n",
    "    LOSS_WEIGHTS = {'rpn_class_loss': 1.0, \n",
    "                    'rpn_bbox_loss': 0.5, \n",
    "                    'mrcnn_class_loss': 1.0, \n",
    "                    'mrcnn_bbox_loss': 0.5, \n",
    "                    'mrcnn_mask_loss': 0.1}\n",
    "    \n",
    "    ROI_POSITIVE_RATIO = 0.6\n",
    "    \n",
    "    DETECTION_MAX_INSTANCES = 3\n",
    "    MAX_GT_INSTANCES = 3\n",
    "    \n",
    "    STEPS_PER_EPOCH = len(train_set.image_ids)//BATCH_SIZE\n",
    "    VALIDATION_STEPS = len(test_set.image_ids)//BATCH_SIZE\n",
    "    \n",
    "config = mConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", model_dir = MODEL_DIR, config=config)\n",
    "# model.keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_weights = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_weights == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_weights == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(DEFAULT_WEIGHTS, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_weights == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last()[1], by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import imgaug\n",
    "from imgaug import augmenters as iaa\n",
    "np.random.bit_generator = np.random._bit_generator\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Sometimes(0.5, [iaa.Fliplr(0.5)]),\n",
    "    iaa.Sometimes(0.5, [iaa.Flipud(0.5)]),\n",
    "    \n",
    "    iaa.Sometimes(0.5, [iaa.Rot90(k=1)]),\n",
    "    iaa.Sometimes(0.5, [iaa.Rot90(k=2)]),\n",
    "    iaa.Sometimes(0.5, [iaa.Rot90(k=3)]),\n",
    "\n",
    "    iaa.Sometimes(0.1, [iaa.Crop(px=(1, 16), keep_size=True)]),\n",
    "    iaa.Sometimes(0.1, [iaa.GaussianBlur(sigma=(0, 3.0))]),\n",
    "    iaa.Sometimes(0.9, [\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, \n",
    "            translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05)}, \n",
    "            rotate=(-5, 5), \n",
    "            shear=(-2, 2),\n",
    "            order=[0, 1], \n",
    "            cval=(0, 255), \n",
    "            mode=imgaug.ALL \n",
    "        )\n",
    "    ]),\n",
    "    iaa.Sometimes(0.5, [iaa.AdditiveGaussianNoise(scale=(1, 3))]),\n",
    "    iaa.Sometimes(0.95, [iaa.LinearContrast(alpha=(0.7,1.3))]),\n",
    "    iaa.Sometimes(0.05, [iaa.CLAHE(clip_limit=(1,5))]),\n",
    "    iaa.Sometimes(0.1, [iaa.ElasticTransformation(alpha=9, sigma=9)]),\n",
    "    iaa.Sometimes(0.01, [iaa.PiecewiseAffine(scale=(0,0.015))])\n",
    "], random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training - Stage 1\n",
    "# Finetune network heads\n",
    "model.train(train_set, test_set,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=3,\n",
    "            layers='heads',\n",
    "            augmentation=seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train(train_set, test_set,\n",
    "#             learning_rate=config.LEARNING_RATE,\n",
    "#             epochs=6,\n",
    "#             layers=\"11M+\",\n",
    "#             augmentation=seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training - Stage 3\n",
    "# Finetune all layers\n",
    "model.train(train_set, test_set,\n",
    "            learning_rate=config.LEARNING_RATE ,\n",
    "            epochs=7,\n",
    "            layers='all',\n",
    "            augmentation=seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mobile_mask_rcnn_abovo2.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keras_model.save('mobile_mask_rcnn_abovo_allmodel2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keras_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file('mobile_mask_rcnn_abovo_allmodel2.h5')\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_file = open('mobile_mask_rcnn_abovo_allmodel2.h5', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# model = model_from_json(loaded_model_json)\n",
    "# model.load_weights(args.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(mConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.5\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()[1]\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../logs/512_mmrcnn_abovo20200326T0552/mask_rcnn_512_mmrcnn_abovo_0004.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test on a random image\n",
    "# image_id = random.choice(test_set.image_ids)\n",
    "# original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "#     modellib.load_image_gt(test_set, inference_config, \n",
    "#                            image_id, use_mini_mask=False)\n",
    "\n",
    "# log(\"original_image\", original_image)\n",
    "# log(\"image_meta\", image_meta)\n",
    "# log(\"gt_class_id\", gt_class_id)\n",
    "# log(\"gt_bbox\", gt_bbox)\n",
    "# log(\"gt_mask\", gt_mask)\n",
    "\n",
    "# visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "#                             test_set.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            test_set.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "# image_ids = np.random.choice(test_set.image_ids, 10)\n",
    "APs = []\n",
    "stat=[]\n",
    "l=[]\n",
    "for image_id in tqdm.tqdm(test_set.image_ids):\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(test_set, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    \n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "#     print(gt_class_id, r['class_ids'])\n",
    "#     print(AP,precisions, recalls)\n",
    "\n",
    "    stat.append([gt_class_id, r['class_ids'], gt_bbox, r[\"rois\"], r['scores']])\n",
    "\n",
    "\n",
    "    l.append(len(r['class_ids']))\n",
    "    \n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))\n",
    "stat = np.array(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "res=[]\n",
    "for y,yhat,rbox,pbox,scores in stat:\n",
    "    maxiou = 0\n",
    "    cls = 7\n",
    "    ssc = 0\n",
    "    for box,i,sc in zip(pbox,yhat,scores):\n",
    "#         print(box,rbox)\n",
    "        iou = bb_intersection_over_union(box,rbox[0])\n",
    "        if iou>maxiou and iou>0.5:\n",
    "            maxiou = iou\n",
    "            cls = i\n",
    "            ssc=sc\n",
    "#     print(y,cls,ssc)\n",
    "    res.append([y[0],cls])\n",
    "#     if n>10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.array(res)[:,1]\n",
    "real = np.array(res)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(list(real), list(yhat), labels=[1,2,3,4,5,6])\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax); \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels([1,2,3,4,5,7]); ax.yaxis.set_ticklabels([1,2,3,4,5,7]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i,j in res:\n",
    "    l.append(i==j)\n",
    "sum(l)/len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-root",
   "language": "python",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
